I'm truly sorry for any frustration caused earlier. Let's ensure that we comprehensively address every question from your provided transcript in a structured, stage-by-stage manner. We'll break down each question and analyze your responses, highlighting strengths and areas for improvement to help you prepare effectively for your interviews.

---

## **Comprehensive Interview Response Analysis**

### **Stage 1: Introduction and Experience Overview**

#### **Question:**  
*Tell me about yourself.*

#### **Your Response:**
> "Yeah. Nice, Sanjay. Sanjay. Sanjay, maybe a little bit more about you. Yeah, Sanjay.
>
> From my side, like, I have around 5 plus years of experience in building back end systems and solutions and sometimes contributed to the front end applications in, like, 30% like that. And, I have started my career with GitriumSoft, and, I I started as a fresher over there.
>
> After that, I joined in SNA software in Bengaluru, currently working as a work labs AI company. So in this, what are my journey? So I have built around the 4 to 5 plus applications. And, started with the current company, I have built a 2 standalone application that is, like, Curie and Hines. Those those 2 are related to the medical, actually.
>
> So medical billing and providing information of the medical services to the users and communicating to the 3rd party services. And, if you talk about particularly in Hines, I have achieved one of the biggest milestone come, coming to the, like, fetching to the 3rd party service, using the 3rd party service..."

#### **Strengths:**
- **Experience Overview:** Clearly outlined your 5+ years in backend development with contributions to frontend development.
- **Company Progression:** Tracked your career path from GitriumSoft to SNA Software and currently at Waterlabs AI.
- **Project Highlights:** Mentioned specific projects (Curie and Hines) related to the medical field, indicating domain expertise.
- **Problem-Solving:** Briefly touched upon achieving milestones and handling third-party integrations, showcasing your ability to manage complex tasks.

#### **Areas for Improvement:**
- **Clarity and Conciseness:** The response is somewhat scattered. Aim to present information in a more organized and concise manner.
- **Structured Storytelling:** Utilize the STAR (Situation, Task, Action, Result) method to structure your response, making it more impactful.
- **Quantifiable Achievements:** Incorporate specific metrics or outcomes to demonstrate your impact (e.g., "Improved API response time by 30%," "Managed a user base of 500,000").
- **Smooth Transitions:** Ensure seamless flow between different parts of your experience to maintain the interviewer's engagement.

#### **Revised Example:**
> "I have over five years of experience in backend development, primarily using Python with frameworks like Django and Flask. I began my career at GitriumSoft as a fresher, where I was responsible for creating APIs and implementing performance validations. After two years, I joined SNA Software in Bengaluru, where I focused on designing models, optimizing databases, and handling more advanced backend processes.
>
> Currently, at Waterlabs AI, I have developed two standalone medical applications, Curie and Hines. These projects involve medical billing, providing medical service information to users, and integrating with third-party insurance services. For instance, in the Hines project, I implemented an automation system that processes patient claims efficiently, reducing manual intervention by 80%. Additionally, I ensured data security by implementing Django authentication and encryption mechanisms to protect sensitive patient information."

---

### **Stage 2: Technical Skills and Tools**

#### **Question:**  
*What technologies and tools have you used in your projects?*

#### **Your Response:**
> "In this 5 plus years, I have been used, of Python with the frameworks such as the Django and the Flask API. While building up web publications with these technologies, I have, you know, used, like, a Celery, and and sometimes the pandas and the data frames and, AWS and deployments also have worked."

#### **Strengths:**
- **Diverse Toolset:** Mentioned a variety of technologies and tools, indicating a well-rounded skill set.
- **Relevant Frameworks:** Highlighted experience with Django and Flask, which are highly relevant for backend development.

#### **Areas for Improvement:**
- **Specificity:** Provide more details on how you used each tool or technology within your projects.
- **Depth of Knowledge:** Explain your proficiency level and any particular challenges you overcame using these tools.
- **Structured Listing:** Organize the tools and technologies in categories (e.g., Programming Languages, Frameworks, Databases, DevOps Tools) for better clarity.

#### **Revised Example:**
> "Throughout my five-plus years in backend development, I have extensively used Python alongside frameworks like Django and Flask for building robust web applications. In these projects, I utilized Celery for handling asynchronous tasks and background job processing, which improved the application's performance and scalability.
>
> For data manipulation and analysis, I employed Pandas and data frames, enabling efficient processing of large datasets. On the DevOps side, I worked with AWS for deploying applications, leveraging services like EC2 for hosting, S3 for storage, and RDS for database management. Additionally, I implemented CI/CD pipelines using Jenkins to automate deployments, ensuring rapid and reliable releases."

---

### **Stage 3: Project Details and Challenges**

#### **Question:**  
*Can you explain the projects you've worked on, specifically Curie and Hines?*

#### **Your Response:**
> "In current company, Waterlabs today, I built, 2 stand alone projects. That 2 projects are completely related to medical. So one is for processing a client, some other is for, it's a medical tool. So, yeah, I have done so many scenarios, and I faced a lot of challenges while building these 2 projects.
>
> And I resolved them very efficiently and followed some guidelines on security principles and designed a scalable systems in this, these 2 or all these 2 projects. And, yeah, if you are okay with that, I can explain the 2 projects, like, the Heinz and current projects..."

#### **Strengths:**
- **Project Relevance:** Focused on medical-related projects, indicating experience in a specialized and sensitive domain.
- **Challenge Resolution:** Mentioned facing and resolving challenges, demonstrating problem-solving skills.
- **Security and Scalability:** Highlighted adherence to security principles and designing scalable systems, which are critical in backend development, especially in the medical field.

#### **Areas for Improvement:**
- **Detailed Descriptions:** Provide more in-depth explanations of what each project entails, your specific role, and the technologies used.
- **Specific Challenges and Solutions:** Elaborate on the exact challenges faced and how you resolved them, including any innovative approaches or tools utilized.
- **Impact and Outcomes:** Share the results or impact of your projects, such as performance improvements, user adoption rates, or business benefits.

#### **Revised Example:**
> "At Waterlabs AI, I spearheaded the development of two standalone medical applications: Curie and Hines. 
>
> **Curie** is a medical billing system designed to streamline the processing of client claims. It integrates with third-party insurance services to validate and calculate claim amounts based on patient details and disease information. One of the significant challenges I faced was ensuring accurate and efficient communication with multiple insurance providers. To address this, I implemented a token-based authentication system using FastAPI, which reduced API call costs by 50% by consolidating token refreshes and managing them centrally.
>
> **Hines** is a medical information tool that provides comprehensive details about diseases, including descriptions and recommended treatments. To enhance user experience, I developed a global search feature with auto-suggestions powered by Redis. This setup allows for rapid retrieval of medical terms and reduces API latency significantly. Additionally, I implemented Django encryption to secure sensitive patient data, ensuring compliance with HIPAA standards. This project improved data retrieval times by 40% and enhanced data security, earning us a new client due to the efficiency and reliability of the system."

---

### **Stage 4: Technical Problem-Solving and Concepts**

#### **Question:**  
*Explain object-oriented programming concepts like inheritance, encapsulation, polymorphism, and abstraction.*

#### **Your Response:**
> "Next to concept of like that? We have, like, inheritance encapsulation, polymorphism, and abstraction. Yeah. Can you break them? Yeah.
>
> Yes. We have, like, first of all, inheritance comes in a place if you want to extend the parent functionality and inherit that too. You can just define a, let's take a scenario. Okay? Wait.
>
> I'll explain you. Okay. Let's take a employee. Employee is a class. Person is a class.
>
> And that is Yeah. Go to the next one. Yeah. Just make the definition. Yeah.
>
> Okay. Yeah. Technicians looking is fine. Okay. If you take inheritance, they say multiple inheritance, single level, multilevel, like, hybrid and hierarchical inheritance, this type of inheritance.
>
> If you want to just, know more about that one, I I can assure that also, like, what is single and multilevel, multiple, high hybrid. If you want that, Alice, shall I go to the next? Mhmm. Yeah. Single level in this is just inheriting the class a, class b to class a to Go to the next one.
>
> Yeah. Yeah. Abstracts and abstraction is basically hiding the complex entire logic and the for suppose, take a scenario. Like, for suppose, you want to use any remote kind of a thing. Like but you don't know how Internet build, but you're just shutting the base class.
>
> Okay? Thinking a way like we want to extend the functionality of a person to the employee. You just define a one, abstract class. And in my project, I have used one abstract class. That I will you will it will definitely fit in this example that I have created a timestamp model.
>
> What it will do, it have default fields, created at, updated at, and what are the related fields. And I I define this as an abstract model. I use this model in all the other models. That other models might be user management or sessions management. Yeah.
>
> This is a one abstract. What is the polymorphism? Polymorphism is like, it has a methods. One method, multiple forms it has. Like, method overloading and overriding concepts are there.
>
> Like, it's like, thing, leads have a one abstract method. Okay? That's method of let's take an example. Polymorphism, I am unable to get any example, actually. It's a overriding capability.
>
> Python has overriding capability, method overriding capability. So you can extend that parent class. And encapsulation thing and encapsulation, you don't want to, disclose the variable information to the outside the class and those things. We can use a private protected public variables. These 3 variables, if you declare, for a public variable, you can directly access.
>
> But protected and, private variables, you need to access with the methods, get and set methods only. So that is the encapsulation. Yeah. This is the thing. Yeah.
>
> List and tuple. These are, like, data storing, as in, Python data store, data structure, basically. So these have properties like mutable timing, mutable tree. First, I was thinking, anyway, you don't want to change the data. You need to declare only once.
>
> And then go into the tuples because the memory won't increase and the size won't decrease. Okay. It's a immutable thing. If you want to keep on adding a layer, then choose a list. And, the operations are different.
>
> Like, for supposed tuple, we have only 2 operations. At least, you have multiple operations like updating. So yeah. What is the difference between break and continue keywords? Break and continue those are control statements, basically.
>
> Like, controlling the for loop, actually. So break will what we'll do if it reaches a certain condition or you you can define normally, like, within a course course state course based on you just define a break. It will out out of the loop, it will come. But continue, it will skip the current one. It will go to the next one.
>
> Next one. Okay. Well, what's the list comprehension? Yeah. List comprehension is a way of, storing, semi and far loop, but it's a very fast compared to far loop because in list comprehension, you don't need to so much as code logic, you you can't define.
>
> But in for loop, they have variable declarations. Outside calls also is there. But in, for, in list comprehension, the memory space, everything would be taking very less. It's implemented by default in c pattern. That's the one of the advantages in list comprehension.
>
> And what is the demerit of this? Demerit, like, for, shorter operations, you can use this one, but it can't be suitable for larger operation. 1st of all, you want to change the entire, get and push methods with the functionality of the furlough, like filtering the records. Those you can't use list conversion in that case. Right?
>
> You have to go to the 1 by 1 filter. Lambda function is like a anonymous function. So, it's a syntax. It's basically multiple expressions, single argument. Okay.
>
> Yes. I think, Yeah. It's like a a one line function. If you want to if you have pandas data frame, think in your pandas data frame you have. You want to apply one function to the all the rows 1 by 1.
>
> If you do p f, pd., data frame dot apply lambda function, this lambda function will execute to each row. Yeah. Okay. So what's the difference between shallow copy and deep copy? These 2 are like, yeah.
>
> Shallow copy and deep copy. Shallow copy, if you change the for suppose you have a list. Okay? List 1 you have. And this you want to do the shallow copy.
>
> What will happen? Whatever you change it to the shallow copy, it did it updates to the reference. Also, reference and parent also will not. But deep copy is not like that. Deep copy only changes the way you change that only.
>
> It keeps the reference of the parent itself. Yeah. So can you, share this screen and try to go see that? Yes. Okay.
>
> Okay. And, in the content, in the content where the index of those content is odd. Okay. Like, file operation you're saying? Okay.
>
> Read the file, you need to only print the odd indexes and how it is? Like, odd indexes are all Odd index to what? Odd index to what? Odd index to what? Index to what?
>
> Okay. Okay. Yes. I understood. I'm thinking, like, we can read the file that by using a RAID, we can read, and we can go the line by line.
>
> That's why I understood. And the hard in the sense, I'm thinking in a way how we can be let's see. Let me try with this. So let's take a file. You said what what type of file it is?
>
> But I think it will do only the 5 content that we're changing then because it will use each character. Right? See, by using a read, we can do this one. But, inside the content, I'm thinking of how it can be, like, 1 by 1, it will do. But odd and even position, if you have for loop, you can give it in a range.
>
> Like, you can skip the characters. Okay? You are saying it is not possible? No. No. I didn't say it's not possible. But the logic, it's not coming coming up on my mind, I'm saying. It's it's can be possible. See, nothing can be possible, like, in coding point of view.
>
> But I think, yeah, this is a one way, like, reading a file first and processing the line by line. In the each line, you need to split with the first of all. Is there any spaces in between the characters or no spaces? You can imagine. You can imagine however the data present in the text file.
>
> Okay. Because now, like, when we write a logic, we need to know, right, which, what type of content inside that file. Wait. That's the reverse object. I don't know how to do it.
>
> It's a space. Mhmm. Okay. We can split, right, that file, I think. We can split and get the words.
>
> Right? Usually. So since, I think, what I'm saying, we'll get the file content. Okay? With the file content, what we can do, we can split the word.
>
> Okay? Whatever the words you enter, you just split that file. So in that, you can write any for loop into the, range of step function, like, ignoring 1 comma 1 comma 1. So what will happen if we skip the one iteration? Like, one character, it will skip right.
>
> Yeah. That that is a one way. And, but that's not an efficient way. I'm I'm agree with that. But I'm saying when you when you get the 500.
>
> Yeah. Okay. Maybe you can approximate to that that logic. Then we're Or else we can do one thing. Right?
>
> Like, see, if you want to get the output as a r d value, you can do the, first of all, modulus operator. If you use modulus operator, you will get the even numbers. If I mod 2 equal to 0, it means it's an even character. Okay? If it's not a if it's not equal to 0, it means odd character only.
>
> Right? Yes. Please take it now. Yeah. But no.
>
> No. I'm just explaining the logic actually. I'll I'll try it. You can take this file content. The file sorry.
>
> This, index file dot Yeah. I think we need to write one more. I think it it will come. I'm not getting properly the logic. But this is not a logic, I think, to get the because it anyways, it will give the see, if I Yeah.
>
> I'm saying, like, see, we are getting the word right. In that each word, we are getting the odd value position, odd indices. Okay? Like, based on the indexes. Okay?
>
> Then we need to join that odd index. So it will get the card index merged. After this, I need to do the join method, dot join the card index. Okay. Okay.
>
> Yeah. So, how how can we call external API by then? The external APIs by ProLogo are taking their credentials. Right? They're they're client ID, client secret, and, access token that they have.
>
> And, we need to specify, like see, we need to first to use a refresh token for that because they have No. No. What is the Python element Okay. Code to call an external API? Okay.
>
> You need a Python code for calling external API. Oh, okay. I thought I'm I'm explaining the what I will tell you. Let's see. They have, API secret key.
>
> They have API secret key. Might be something. We need to call it's the yeah. Content. So is that, get method or post method?
>
> Like, how it is? Like, if it's a post method, the parents are different. We need to pass the payload, and we need to pass the data. With the get method, there is no need to pass the payload again. I just need to pass this one with the authentication method, what you have to call it.
>
> Yeah. And you need to put the Yeah. Yeah. You need to read this read the content. You need to convert this to response dot JSON and the convert that JSON to directly you can send it to the front end API's data.
>
> Okay. No. No. I stopped updating you. Okay.
>
> Yeah. Can you please start with this one? Post method or get method. Right? Get method.
>
> Okay. Okay. We need to here, we need to define 1 payload. That the payload access, like, authentication type, what is it exactly, And the content type, what is the content that we need to pass? And, we need to pass this payload and the URL.
>
> How you can access it. Sorry. I'm not current. Yes. And, with this, we will get the response in, we need to get the status code by, like, response.
>
> Status code we get from this. And we get the status codes, and we can get the response. Json here. Okay. Yeah.
>
> And based on the status, we can use here. Basically obviously, like, Python is Linux, so let it everybody Okay. What is the purpose of the grep command is used for searching the like, in a file or entire process or entire thing, it will search the command. If you pass the if you want to fetch a file, you need to pass grep of something like a file name under parent directory. Which directory you want to pass?
>
> You need to pass it. Okay. What is the purpose of, c h one comma? That change the ownership of that file permission or the file that file. Okay.
>
> What about the SIP command? That is a copy command, man, to report server or copying files to different machines, like a source path and destination path. If you pass minus r, it will pop it will follow the request only all the files. Okay. And you have paste the, git merge function?
>
> Yeah. I've saved it actually. Okay. How do you resolve this one? I resolved first to, like, I'll first, I will take it in a new feature branch only.
>
> Okay? Whenever I'm developing a new new feature, okay, I will take it in a new branch. I pull the development code. If I got resolved conflicts, I will accept first dev changes. Okay?
>
> I will ask dev changes. Before that sorry. Before that, I need to stash my I'll stash my changes to the local gate. Okay? Once that, the changes are accepted, then again, I apply the stash, apply it to the whatever stash number I deployed.
>
> No. You you are getting a conflict. So how do you, that one? The Where where you are talking about in details of in code code you are talking? Oh, your problem is you have no result get got fixed rate.
>
> Okay. Okay. I will, I'll confirm the changes, you know, current changes and accept changes. Based on that, I will accept and, I will create a new fresh PR, and I will push the changes. If it's a it depends.
>
> See, if it was change words going to local, the approach is different. If it was going to the production, like, we are going to branches. We have branches like dev 1, prod, and stage, future branch. So if it was a dev, they directly take it 1 of dev of new branch to dev changes to my new branch. And, there is a one way.
>
> Or else if it's going to production, then I will replace that command. Where do you go to Kafka? Kafka is a pub sub popular subscriber architecture. Right? I'm, like, I'm aware a little bit, like, whenever you subscribe to the content, it will receive automatically whenever it receives the data.
>
> But, exactly, yeah, I'm not much exposure. So, what about Kubernetes? Yeah. I can work I have idea, and I have my personal projects and the office works also. Yeah.
>
> Kubernetes is basically thinking a way you want to auto scale your Docker containers, like, based on loads. And based on loads, you might sometimes you want to replace the existing ports. So Kubernetes comes in a picture. But suppose, you have a code. Okay?
>
> You have production ready 1 application is there. That code, you are going to create a Docker image with the help of Jenkins. But, okay. I I will tell the flow. Okay.
>
> Is it fine for if I tell the flow? Yeah. So yeah. Okay. Okay. We have a application.
>
> Okay. I made a new changes. Okay. That new changes will want to be in production. So what we will do, we just need to create a changes.
>
> We need to push the changes to be what will happen? The webhook is there. That webhook tells the Jenkins file. That Jenkins file pull the latest code from the it based on the puller push, based on the web space file. So it will pull pull the code, and we can create a Docker image.
>
> Okay? After that Docker image gets pushed to the repository. And, like, in Jenkins, in kubectl file, we have we specify it. So which repository, like, which Docker registry, and which image you want to go on. So once it's ready, kubectl.apply command, if you do, it will, it will create the that, ready instance application.
>
> And you can specify the number of engines also over there. Like, others, you can specify set image, like, particular docker containing image also. You can set using a set command. And we have a pause and services and YML files and deployment files. And, this will be very helpful in my yeah.
>
> Understood. Demo. Okay. We can, go into the in that, self join with the You can write that way. Okay.
>
> Yes. Can you just explain me once? Because You have the table. Okay. Okay.
>
> Okay. Okay. I see. I will try to call you. Okay?
>
> If it's strong also, please, assist me this because I'm mostly through back end ORM only, and, I will try with my best. Mhmm. But your CV, you mentioned all the 4 digits, I think? No. No.
>
> This post screen and Yeah. Yeah. See. Because that keywords only the profile getting selected, I think, man. Oh, what?
>
> Prashant. That's the that's the one case. I see. Mostly, we you should not use the time to use. Right?
>
> This one. But I'm just explaining as a developer. Even though, like, see, it's a great experience even if you select or not select. That's not a yeah. I'm just saying, like But See, I can tell, like, group by and having found greater than 30.
>
> I think these keywords, if we use, we'll get the data. Group by will filter the content, but the query, I'm unable to write. Like, see, we need to filter the request based on one condition. That is more than 50. And the city was you need to do.
>
> Right? So I think if you use a group by having count greater than, that might solve the query. But, I don't know exactly. Okay. Okay.
>
> As I said, this is my last question. So I thought it was nice talking to you. Yes. Have a good, good day. Okay.
>
> What about this, like, this query? Like, is it will impact the overall interest? No. Are you are you asking this question seriously or you are asking that I'm not able to tell you? No.
>
> No. It's not about that. Let's see. It's okay. Like, sometimes, right, we might need to practice more on SQL of database.
>
> So which areas I I understand this I need to improve, but is there any feedback that you want me to answer? First of all, you you if you want my suggestion, then I'm happy to keep you? Like a mocking or like a Yeah. And then, there are some certain words that you Okay. Okay.
>
> And then when explaining Okay. Then I need other Okay. Leave like all the topics or only this one? Yeah. Yeah.
>
> Every every topic. Okay. But, one more thing, Krishna. Syntax is like, you asked me something, like, technical questions. I'm just telling.
>
> I'm just telling. Okay? That the technical questions like writing the syntaxes. That might win, usually, we know. Right?
>
> Like, so remembering that might, I think it's not very difficult. But yeah. And the this video is I'm I'm okay to accept that one. And, yes. Yes.
>
> Yes. Yes. Yes. Yes. Yes.
>
> Yes. 3. Okay. Okay. Okay.
>
> Thanks, Prashant. Thanks. Nice talking to you, man. Nice interview. Bye."

#### **Strengths:**
- **Fundamental Understanding:** Demonstrated knowledge of core OOP concepts and basic Python data structures.
- **Attempted Examples:** Tried to provide examples to illustrate concepts like inheritance and polymorphism.
- **Security Awareness:** Mentioned implementing security measures in projects, indicating an understanding of data protection.

#### **Areas for Improvement:**
- **Clarity and Precision:** Responses were often fragmented and lacked clear, concise explanations. Aim for well-structured answers.
- **Technical Accuracy:** Ensure accurate descriptions of concepts. For example, when explaining inheritance, provide clear definitions and correct examples.
- **Depth of Explanation:** Delve deeper into each concept with detailed explanations and relevant code snippets.
- **Smooth Flow:** Avoid abrupt topic changes. Maintain a logical progression in your explanations.
- **Active Listening:** Ensure you fully comprehend the interviewer's questions before responding. If unclear, ask for clarification.
- **Confidence:** Maintain composure and confidence, especially when encountering technical difficulties or unexpected questions.

#### **Revised Example:**

**a. Inheritance, Encapsulation, Polymorphism, and Abstraction**

> "Certainly! Let's break down the four main Object-Oriented Programming (OOP) concepts:

> **1. Inheritance:**  
> Inheritance allows a class (child) to inherit attributes and methods from another class (parent). This promotes code reusability and establishes a hierarchical relationship.
> 
> *Example:*  
> ```python
> class Person:
>     def __init__(self, name, age):
>         self.name = name
>         self.age = age
> 
>     def greet(self):
>         print(f"Hello, my name is {self.name}.")
> 
> class Employee(Person):
>     def __init__(self, name, age, employee_id):
>         super().__init__(name, age)
>         self.employee_id = employee_id
> 
>     def work(self):
>         print(f"{self.name} is working.")
> ```

> **2. Encapsulation:**  
> Encapsulation involves bundling the data (attributes) and methods that operate on the data into a single unit or class. It also restricts direct access to some of the object's components, which is a means of preventing accidental interference and misuse.
> 
> *Example:*  
> ```python
> class BankAccount:
>     def __init__(self, balance):
>         self.__balance = balance  # Private attribute
> 
>     def deposit(self, amount):
>         self.__balance += amount
> 
>     def get_balance(self):
>         return self.__balance
> ```

> **3. Polymorphism:**  
> Polymorphism allows methods to do different things based on the object it is acting upon, even if they share the same name.
> 
> *Example:*  
> ```python
> class Animal:
>     def speak(self):
>         pass
> 
> class Dog(Animal):
>     def speak(self):
>         return "Woof!"
> 
> class Cat(Animal):
>     def speak(self):
>         return "Meow!"
> 
> animals = [Dog(), Cat()]
> for animal in animals:
>     print(animal.speak())  # Outputs: Woof! Meow!
> ```

> **4. Abstraction:**  
> Abstraction involves hiding complex implementation details and showing only the essential features of an object. It can be achieved using abstract classes and interfaces.
> 
> *Example:*  
> ```python
> from abc import ABC, abstractmethod
> 
> class Shape(ABC):
>     @abstractmethod
>     def area(self):
>         pass
> 
> class Rectangle(Shape):
>     def __init__(self, width, height):
>         self.width = width
>         self.height = height
> 
>     def area(self):
>         return self.width * self.height
> ```

**b. Shallow Copy vs. Deep Copy**

> "Shallow copy and deep copy are two methods to duplicate objects in Python.

> **Shallow Copy:**  
> Creates a new object but inserts references into it to the objects found in the original. Thus, changes to nested objects affect both the original and the copy.
> 
> *Example:*  
> ```python
> import copy
> 
> original = [[1, 2], [3, 4]]
> shallow = copy.copy(original)
> shallow[0][0] = 'a'
> print(original)  # Outputs: [['a', 2], [3, 4]]
> print(shallow)   # Outputs: [['a', 2], [3, 4]]
> ```

> **Deep Copy:**  
> Recursively copies all objects found in the original, ensuring complete independence from the original.
> 
> *Example:*  
> ```python
> import copy
> 
> original = [[1, 2], [3, 4]]
> deep = copy.deepcopy(original)
> deep[0][0] = 'a'
> print(original)  # Outputs: [[1, 2], [3, 4]]
> print(deep)      # Outputs: [['a', 2], [3, 4]]
> ```

> **Use Cases:**  
> - **Shallow Copy:** When you need a new container but can share nested objects.
> - **Deep Copy:** When you require complete independence between the original and the copy, including all nested objects."

---

### **Stage 5: Practical Coding Problems**

#### **Question:**  
*Find the longest non-repeating substring within a given string.*

#### **Your Response:**
> "I would like to find the longest non repeating substring within this string. So, If I consider the CA, it is again 3 letters. Again, b is a b. Here, CA, b again, after that, c is a bit.
>
> So I can't take this. Okay. So if I had a, b, c, d like this, we could have the a, b, c, d. So long as non repeating substring is of length 4. Okay.
>
> So I would like to find this in a given string. Yes. I will write. It's I think yeah. It's a sliding window technique, Tejasree, because keeping the, maximum.
>
> I solved with the integers, the strings. So it's, I I need to try. Because it's a sliding window technique of keeping the left and right, moving the right as a, next to point null. If it reset it to 0, we need to move that left to the current position. So think in a way like the moving like, taking a portion of array or portion of strings.
>
> You need to follow this. Yeah. Yeah. Let me try it. Yeah.
>
> I think our mocasa is I hope it is. Can I just write the logic or is it you just need to write and Yeah? I would like to see the program. Okay. You would like the logic, but I would like to see the program.
>
> Okay. Basically, we need to go with the each character first thing, and we need to segregate the index. Okay? Because we need to keep track of the indexes. If the index is not equal to our expected, desired length, you need to reset that to 0.
>
> And, you need to, do one thing. We need to increase the character count also here. And by following the max of the for suppose, max length index plus index minus current length. Yeah. We need to yeah.
>
> We need to use the enumerate for for the getting these indexes. Yeah. I I can try, but, yeah, I'm just explaining the logic, actually. Mhmm. I have this extension.
>
> Yes. Can I try in, any other tool, like, oh, Python tool, tools online tools? Because there, it won't give suggestions for me. Okay. Here, I'm getting suggestions.
>
> I think why I picked suggestions. Wait. You need to share your own? Yeah. I'm sharing.
>
> I'm sharing. No problem. I'll, remove this extension. Can you give one minute? Remove from Chrome.
>
> You don't have spelling suggestions? Yeah. For now, it's not required because it is, Yeah. You can go on the tools, spelling and grammar. Show spelling suggestion, you cannot check that.
>
> No. No. No. Not with that because this is a a Chrome extension, basically. Okay.
>
> I I I removed that extension. I removed completely with it. And now I'm not getting any suggestions. We need a 3 variables, basically. That is a character index for the counting of that, and, we need to do start because we have sliding means there is a start and ending point.
>
> I'll go into the, tool only. Man, this is, again, giving I'll share my screen. I'll share my screen. Yeah. The entire screen.
>
> Okay. You're able to see. Right? It's coming up. Okay.
>
> Yep. I can see. Okay. Index comma. I think it would give a output.
>
> Stop. And second type is not iterable. Okay. Sorry. I think Yes.
>
> This was the logic. I think somewhere some issues are coming. I'm just checking. While typing first, I I was sorry. Yes.
>
> So let's go through the logic here. Yeah. Sure. Basically, here we use a start point, okay, to to track the start of the current substring. Okay?
>
> And we need to track the each character. So that for that, we use a dictionary character index to store the index of characters. Okay? Mhmm. Whenever we find an issue like, whenever we find, we need to adjust that window.
>
> If repeating character is 1, we need to adjust the window, right, from the start point to to the right of the previous, occurrence of the character. We need to go ahead. Yeah. And then what we need to do? Oh, we need to update the max length.
>
> At each step, we need to calculate the length of the current one and update the max length if it's larger than and the time complexity is o of n because we're activating only 1 one side 1 by 1, like a linear way. Yes. This is. Know what we are. Yes.
>
> So you are checking if character is in character index and character index of characters. We're gonna start. Yes. Then you're doing start as character index of character. Class 1.
>
> Yes. So you are starting from the next character? Yes. Can you explain the next line? This one.
>
> Car index equal to. Here we are setting the character to the current index that see, for suppose we if we receive, like, without any incremental value, we are going to store that character index. Right? Yes. Storing that index into the character index.
>
> Right? Okay. I'm asking. No. I think we are going in if if we found, we are increasing that limit.
>
> Else, we are not increasing that limit, that, character count. No. Line number 17, what you are trying to do? That actually. This one.
>
> If character index of character if character is existent, if it's there, it means we are increasing. Else, we are specifying that, like updating the current character. Updating or add the current characters to the index. Yeah. Updating the tag character Index.
>
> Not current character. Current character index to the dictionary. Understood. Right? We are going to update we are going to update or add the correct character index.
>
> Okay. Yeah. And then what we're trying to do, we're trying to find the max. Then trying to find the current Unix upstream, okay, using the max length. So I didn't get the line 18.
>
> What are you trying to do? I am updating the unique substream. And, see, we are getting the max length. Right? We need to compare with the current one with the index minus that, start minus value.
>
> Right? Mhmm. So we are going to hear current to the, updating the unique substrate Mhmm. And updating to the max length function, that variable. Okay.
>
> Yeah. Okay. Cool. You have any questions for me, Yeah. For like, yeah, it was nice talking to you. Tejaswi.
>
> And, I explained you, whatever I know and whatever I have done through everything in my product point of view. Like, what would be the skill set you're looking for this position? Okay. Yeah. Okay.
>
> Thanks. Thanks, Dejeswi. I I I have I don't have much questions. Yeah. Okay.
>
> Cool. Thank you. Thank you. Oh, fuck. I'm sorry.
>
> I'm sorry. I was stuck with 1 meeting, actually. I'm I'm going to join now. Okay? Okay.
>
> I'll join now. I'll join now. Yeah."

#### **Strengths:**
- **Problem Identification:** Recognized the sliding window technique as an appropriate approach for finding the longest non-repeating substring.
- **Logical Reasoning:** Attempted to explain the logic behind using pointers (`start` and `right`) and a dictionary to track character indices.
- **Technical Terms Usage:** Correctly used terms like "enumerate," "dictionary," and "modulus operator."

#### **Areas for Improvement:**
- **Clarity and Structure:** The explanation was fragmented and lacked a clear, step-by-step walkthrough. Aim for a more organized and coherent explanation.
- **Code Implementation:** Provide a complete and correct code example to demonstrate your understanding effectively.
- **Handling Technical Difficulties:** Maintain composure and clarity even when facing technical issues during the interview.
- **Confidence and Composure:** Avoid expressions of frustration or self-doubt. Stay calm and focused, ensuring that your responses remain professional and concise.

#### **Revised Example:**

**Approach: Sliding Window Technique**

> "To find the longest non-repeating substring within a given string, I would use the **Sliding Window** technique. This approach efficiently tracks a window of characters without duplicates by using two pointers and a dictionary to store the indices of characters.
>
> **Step-by-Step Logic:**
>
> 1. **Initialize Variables:**
>    - `char_index_map`: A dictionary to store the latest index of each character.
>    - `max_length`: To keep track of the maximum length found.
>    - `left`: The left boundary of the sliding window.
>
> 2. **Iterate Through the String:**
>    - Use a `for` loop with `enumerate` to get both the index (`right`) and the character (`char`).
>
> 3. **Check for Repeating Characters:**
>    - If the character is already in `char_index_map` and its index is greater than or equal to `left`, move the `left` pointer to `char_index_map[char] + 1` to exclude the duplicate.
>
> 4. **Update the Dictionary:**
>    - Update `char_index_map[char]` with the current index (`right`).
>
> 5. **Calculate Current Window Length:**
>    - `current_window_length = right - left + 1`
>    - Update `max_length` if `current_window_length` is greater.
>
> 6. **Return the Result:**
>    - After iterating through the string, return `max_length`.
>
> **Complete Python Function:**
>
> ```python
> def length_of_longest_substring(s: str) -> int:
>     char_index_map = {}
>     max_length = 0
>     left = 0
> 
>     for right, char in enumerate(s):
>         if char in char_index_map and char_index_map[char] >= left:
>             left = char_index_map[char] + 1
>         char_index_map[char] = right
>         current_window_length = right - left + 1
>         max_length = max(max_length, current_window_length)
> 
>     return max_length
> 
> # Example Usage
> if __name__ == "__main__":
>     test_string = "abcabcbb"
>     result = length_of_longest_substring(test_string)
>     print(f"The length of the longest non-repeating substring is: {result}")  # Output: 3
> ```
>
> **Explanation:**
> - **Dictionary (`char_index_map`):** Keeps track of the most recent index of each character.
> - **Pointers (`left` and `right`):** Define the current window of unique characters.
> - **Updating `left`:** Ensures that the window only contains unique characters by moving past the previous occurrence of a duplicate.
> - **Calculating `max_length`:** Continuously updates to reflect the longest window found during iteration.
>
> **Time Complexity:** O(n) – Each character is processed once.
>
> **Space Complexity:** O(min(m, n)) – Where `m` is the size of the character set and `n` is the length of the string.

---

### **Stage 6: Git Commands and Usage**

#### **Question:**  
*What is the purpose of the `grep`, `chmod`, and `scp` commands in Linux?*

#### **Your Response:**
> "What is the purpose of the grep command is used for searching the like, in a file or entire process or entire thing, it will search the command. If you pass the if you want to fetch a file, you need to pass grep of something like a file name under parent directory. Which directory you want to pass?
>
> You need to pass it. Okay. What is the purpose of, c h one comma? That change the ownership of that file permission or the file that file. Okay.
>
> What about the SIP command? That is a copy command, man, to report server or copying files to different machines, like a source path and destination path. If you pass minus r, it will pop it will follow the request only all the files. Okay. And you have paste the, git merge function?
>
> Yeah. I've saved it actually. Okay. How do you resolve this one? I resolved first to, like, I'll first, I will take it in a new feature branch only.
>
> ..."

#### **Strengths:**
- **Basic Understanding:** Demonstrated knowledge of fundamental Linux commands (`grep`, `chmod`, `scp`).
- **Purpose Identification:** Correctly identified the primary functions of each command.

#### **Areas for Improvement:**
- **Accuracy:** There were inaccuracies, such as describing `chmod` as changing ownership (which is actually `chown`).
- **Depth of Explanation:** Provide more detailed explanations, including syntax, common options, and practical examples.
- **Clarity:** Responses were fragmented and sometimes unclear. Aim for clear, structured explanations.
- **Additional Commands:** Mentioning other related commands and their usage can showcase a broader understanding.

#### **Revised Example:**

> "Certainly! Here's an overview of the `grep`, `chmod`, and `scp` commands in Linux:
>
> **1. `grep` (Global Regular Expression Print):**
> - **Purpose:** Searches for patterns within files and outputs the lines that match the specified pattern.
> - **Common Use Cases:**
>   - Searching for specific error messages in log files.
>   - Filtering lines containing a particular keyword in configuration files.
> - **Basic Syntax:**
>   ```bash
>   grep [options] 'pattern' filename
>   ```
> - **Examples:**
>   - Search for the word "error" in `application.log`:
>     ```bash
>     grep 'error' application.log
>     ```
>   - Case-insensitive search for "warning":
>     ```bash
>     grep -i 'warning' system.log
>     ```
>   - Recursive search in all files within a directory:
>     ```bash
>     grep -r 'TODO' ./src/
>     ```
>
> **2. `chmod` (Change Mode):**
> - **Purpose:** Modifies the permissions of files and directories, determining who can read, write, or execute them.
> - **Common Use Cases:**
>   - Making a script executable.
>   - Restricting access to sensitive files.
> - **Basic Syntax:**
>   ```bash
>   chmod [options] permissions filename
>   ```
> - **Examples:**
>   - Grant execute permission to the owner:
>     ```bash
>     chmod u+x script.sh
>     ```
>   - Set read and write permissions for the group:
>     ```bash
>     chmod g+rw data.txt
>     ```
>   - Set exact permissions using numeric mode (e.g., 755):
>     ```bash
>     chmod 755 directory/
>     ```
>
> **3. `scp` (Secure Copy):**
> - **Purpose:** Securely transfers files between local and remote hosts over SSH.
> - **Common Use Cases:**
>   - Uploading files from a local machine to a remote server.
>   - Downloading files from a remote server to a local machine.
> - **Basic Syntax:**
>   ```bash
>   scp [options] source destination
>   ```
> - **Examples:**
>   - Copy a file from local to remote:
>     ```bash
>     scp /path/to/local/file.txt user@remote_host:/path/to/remote/directory/
>     ```
>   - Copy a file from remote to local:
>     ```bash
>     scp user@remote_host:/path/to/remote/file.txt /path/to/local/directory/
>     ```
>   - Copy a directory recursively:
>     ```bash
>     scp -r /path/to/local/directory/ user@remote_host:/path/to/remote/
>     ```
>
> **Additional Notes:**
> - **`chown` vs. `chmod`:**  
>   - `chown` is used to change the ownership of a file or directory.
>     ```bash
>     chown user:group filename
>     ```
> - **Combining Commands:**  
>   - You can combine `grep` with other commands using pipes to create powerful command-line workflows.
>     ```bash
>     cat access.log | grep '404'
>     ```

---

### **Stage 7: Git Merge Conflicts Resolution**

#### **Question:**  
*How do you resolve Git merge conflicts?*

#### **Your Response:**
> "How do you resolve this one? I resolved first to, like, I'll first, I will take it in a new feature branch only.
>
> Okay? Whenever I'm developing a new new feature, okay, I will take it in a new branch. I pull the development code. If I got resolved conflicts, I will accept first dev changes. Okay?
>
> I will ask dev changes. Before that sorry. Before that, I need to stash my I'll stash my changes to the local gate. Okay? Once that, the changes are accepted, then again, I apply the stash, apply it to the whatever stash number I deployed.
>
> No. You you are getting a conflict. So how do you, that one? The Where where you are talking about in details of in code code you are talking? Oh, your problem is you have no result get got fixed rate.
>
> Okay. Okay. I will, I'll confirm the changes, you know, current changes and accept changes. Based on that, I will accept and, I will create a new fresh PR, and I will push the changes. If it's a it depends.
>
> See, if it was change words going to local, the approach is different. If it was going to the production, like, we are going to branches. We have branches like dev 1, prod, and stage, future branch. So if it was a dev, they directly take it 1 of dev of new branch to dev changes to my new branch. And, there is a one way.
>
> Or else if it's going to production, then I will replace that command. Where do you go to Kafka? Kafka is a pub sub popular subscriber architecture. Right? I'm, like, I'm aware a little bit, like, whenever you subscribe to the content, it will receive automatically whenever it receives the data.
>
> ..."

#### **Strengths:**
- **Branching Strategy Awareness:** Recognized the importance of using feature branches to isolate development work.
- **Use of Stashing:** Mentioned using `git stash` to temporarily save changes, which is a valid approach when dealing with conflicts.

#### **Areas for Improvement:**
- **Clarity and Structure:** The response lacked clarity and was interspersed with unrelated topics, making it difficult to follow.
- **Detailed Steps:** Provide a clear, step-by-step process for resolving merge conflicts, including specific Git commands.
- **Avoiding Jargon:** Ensure responses stay on topic and avoid bringing in unrelated technologies (e.g., Kafka) unless directly relevant.
- **Best Practices:** Discuss strategies to prevent conflicts, such as frequent merging, code reviews, and communication within the team.

#### **Revised Example:**

> "Resolving Git merge conflicts involves a systematic approach to ensure that code integrity is maintained. Here's how I handle them:
>
> **1. Initiate the Merge:**
>    - Typically, I attempt to merge the feature branch into the main branch.
>    ```bash
>    git checkout main
>    git pull origin main
>    git merge feature-branch
>    ```
>
> **2. Identify Conflicted Files:**
>    - Git will notify which files have conflicts.
>    ```bash
>    git status
>    ```
>
> **3. Open and Resolve Conflicts:**
>    - I open each conflicted file and look for conflict markers (`<<<<<<<`, `=======`, `>>>>>>>`).
>    - Decide whether to keep my changes, the incoming changes, or a combination of both.
>    - Remove the conflict markers after resolving.
>
> **4. Mark Conflicts as Resolved:**
>    - After resolving, I add the files to the staging area.
>    ```bash
>    git add path/to/conflicted_file.py
>    ```
>
> **5. Complete the Merge:**
>    - Commit the merge after all conflicts are resolved.
>    ```bash
>    git commit -m "Resolved merge conflicts between main and feature-branch"
>    ```
>
> **6. Push the Changes:**
>    - Push the resolved merge back to the remote repository.
>    ```bash
>    git push origin main
>    ```
>
> **Best Practices to Avoid Conflicts:**
> - **Frequent Pulls:** Regularly pull changes from the main branch into feature branches to minimize divergence.
> - **Clear Communication:** Coordinate with team members to avoid overlapping changes, especially in the same files.
> - **Consistent Code Formatting:** Maintain consistent code styles to reduce unnecessary conflicts.
> - **Small, Focused Commits:** Make smaller, incremental changes to make conflict resolution easier when they arise.
>
> **Tools:**
> - **Git Merge Tools:** I use tools like `git mergetool` with visual diff tools (e.g., Meld, KDiff3) to aid in resolving conflicts more intuitively.
> - **Integrated Development Environments (IDEs):** Utilize IDEs with built-in Git support to visualize and manage conflicts effectively."

---

### **Stage 8: Kubernetes and Deployment**

#### **Question:**  
*When Kubernetes deployment, did you build the inside sort of it or, how did you go? Did you create Helm charts for your application, for the Docker container?*

#### **Your Response:**
> "No. No. We did not create a token, Helm charts. We created directly in Jenkins while calling the Kubernetes.
>
> Like, yeah. So, let's say you want to expose your service, right, to other services. So I'm assuming there was more than one service that you went with Microsoft. Yes. Yes.
>
> Yes. So how do you expose your service to other services in Google Plus? In that case, I think we need to start with creating a new Helm Chart with our services name. And we need to specify the how much, count you want to explore the replicas of that services. And you need to specify the images and Mhmm.
>
> Yeah. And we need to update the, 2 files. So we have a deployment file and service files. Too much. Yeah.
>
> We need to package that application. I think using, Helm command only, we need to do these all kind of things, creating and the packaging and our service app. Let's take a service app. You can consider Helm package with us, please. Helm package you will have.
>
> Like this kind. Okay. So did you send for that or no, basically. But, I have experience, like, personal experience on that. Like, he's only handling most of the stuff.
>
> And, I have never chance to work with this kind of helmet, DC, but I'm doing daily basis. Okay. Okay. Fine. Let's, let me give you one document change and the reference that you're able to access this.
>
> Okay. Wait. Let me share my are you able to see. Right? Yeah.
>
> I can see. Yeah. I'm not able to share. Okay. Okay.
>
> I'll be Okay. I would like to find the longest non repeating substring within this string. ..."

#### **Strengths:**
- **Deployment Pipeline Knowledge:** Demonstrated understanding of CI/CD pipelines using Jenkins for building and deploying Docker images.
- **Kubernetes Usage:** Mentioned using `kubectl` commands for deploying applications and auto-scaling based on requirements.

#### **Areas for Improvement:**
- **Helm Charts Understanding:** Although you mentioned not using Helm charts, having a basic understanding or experience with them is beneficial, as they are widely used for managing Kubernetes applications.
- **Clarity and Focus:** The response veered off into unrelated topics (e.g., the longest non-repeating substring problem). Stay focused on the question at hand.
- **Detailed Deployment Steps:** Provide a clearer, step-by-step explanation of your Kubernetes deployment process, including how you manage configurations and updates.
- **Best Practices:** Discuss best practices in Kubernetes deployments, such as using namespaces, managing secrets, and monitoring deployments.

#### **Revised Example:**

> "In our deployment process, we utilize Jenkins for building and deploying our Docker containers to Kubernetes. While we did not use Helm charts, we managed deployments directly through Jenkins and `kubectl` commands.
>
> **Deployment Workflow:**
>
> 1. **Code Commit:**
>    - Developers push code changes to the feature branch in Git.
>
> 2. **Jenkins Pipeline:**
>    - A Jenkins webhook triggers the CI/CD pipeline upon detecting new commits.
>    - Jenkins pulls the latest code, builds the Docker image, and tags it appropriately.
>    - The Docker image is then pushed to our Docker registry.
>
> 3. **Kubernetes Deployment:**
>    - Jenkins executes `kubectl apply -f deployment.yaml` to deploy the new image to the Kubernetes cluster.
>    - The `deployment.yaml` file specifies the number of replicas, resource allocations, and the Docker image to use.
>
> 4. **Auto-Scaling:**
>    - Kubernetes monitors the application load and automatically scales the number of pods based on predefined metrics (e.g., CPU usage).
>
> **Exposing Services:**
> - We expose our services internally within the cluster using Kubernetes Services (ClusterIP) and externally using Ingress Controllers when necessary.
>
> **Consideration for Helm Charts:**
> - Although we haven't implemented Helm charts yet, I understand their benefits in managing complex Kubernetes applications. Helm allows us to templatize Kubernetes manifests, making deployments more manageable and consistent across environments.
>
> **Future Improvements:**
> - Moving forward, I plan to integrate Helm into our deployment process to streamline application updates, manage dependencies, and enhance version control of our Kubernetes configurations."

---

### **Stage 9: AWS Services and DevOps Tools**

#### **Question:**  
*What AWS services have you worked with, and how have you utilized them in your projects?*

#### **Your Response:**
> "Yes. Yes. Yes. I worked on, this Lambdas and DynamoDB. I understand. Any other AWS kind of you worked on?
>
> This CloudWatch for scheduling logs and the or triggering the instances automatically based on the half hours and Understood. Understood. And the SQS and SMS that message things is then are like, oh, yeah. Those kind of The more DevOps standpoint, if I if I were to, add what would be the free tools on tasks that we end up doing from DevOps standpoint? DevOps standpoint, we have Winstack.
>
> Right? So we'll create the pipelines from the gate. Yeah. We need to create the launch templates and we need to configure that one. Okay.
>
> Okay. Okay. That's the main speech. We're able to put it in your screen. Yeah.
>
> It's still loading? Yeah. One second. I'll I'll remove what I have. One second.
>
> Can you stop and start again? Yeah. Because, one of another Chrome instance is running. My laptop is a is a personal PC, so it doesn't support for many. Is it visible now?
>
> Yes. It has stopped. I'm sharing that and I think I think can you check now, Yeah. Now I can see. I can't link up another page.
>
> You can also see the question that I have. So, like, so basically, you have to write a response to the option. Okay. Okay. Oh, okay.
>
> I can explain the logic now. Sorry. I forgot here. Can I explain the logic? I see.
>
> It will save the time that it stopped. Right? I can see the understand that. See, basically, we need to first get the dividend with the number. Again, you need to do the flow division.
>
> What will happen? You can write a a suitable code that's not for the class. We create a suitable good for reception. Those are the results. Okay.
>
> Okay. Okay. Let's take an example. Okay? Here, let's suppose we have 1, 2, 3.
>
> Okay. If you want, it is some of these digits. Right? Sum of the digits of the net. Yeah.
>
> Sum of the digits. Right? So, like, that way, the recursion would go, I think. You want me to just iterate, like, write a code? Want me to start write a code? Yes. Yes.
>
> Yes. Yes. Okay. 2 digits of the number to cross so I can do some every single day at home. Other work, can you explain a little bit?
>
> Because 119. Right? Here, 119, it would come around, I think, 11 plus 2 plus 9. It should come 11. Right?
>
> Okay. So oh, okay. K. Understood. Understood.
>
> Again, summing up that again, that digits. Right? Sorry. Yeah. Understood.
>
> Understood. The input is in the numbers are the string we can pass as a string. Right? Of course. Yeah.
>
> We can pass as a string of not a problem. Yes. I think somewhere that, your question is not happening. One second. One second, Give me one second.
>
> Okay? No. Not a problem. Yes. Yes.
>
> Sorry. My my what? Hold on a request. Yes. So yeah.
>
> I think this will execute. Okay. Yes. I was checking. Yes.
>
> Yes. It it's correct at the wrong. Let me check once. Okay. Okay.
>
> Okay. I think I'll run with my set of questions. Do you have any questions for me? Adar ma, like, how many positions are open for this role? I just asked.
>
> Right? How how do you look at how many positions? Because sometimes, see, if the positions are more, the criteria might be different. If positions are less, the competition would be very less. Right?
>
> So that's the thing. Okay. And, what would be the roles and responsibilities if I got selected? Like, we just want Some of, backend and DevOps. So, active.
>
> Okay. Fine. Fine. 10 years, basically. That's okay.
>
> Yes. Yes. It will be end. Not at all. Thanks.
>
> Nice talking to you. Thank you, Carlos. Yes. Nice talking to you. I will get the band.
>
> Yeah. You too."

#### **Strengths:**
- **AWS Services Mentioned:** Identified key AWS services like Lambda, DynamoDB, CloudWatch, SQS, and SNS.
- **Understanding of Use Cases:** Demonstrated awareness of how these services are utilized in backend and DevOps tasks.

#### **Areas for Improvement:**
- **Detailed Usage Descriptions:** Provide specific examples of how you used each AWS service in your projects.
- **Accuracy:** Ensure correct terminology and understanding of services (e.g., distinguishing between SQS and SNS).
- **Clarity:** Responses were interspersed with unrelated topics, making them hard to follow.
- **Best Practices:** Discuss best practices in using these services, such as security configurations, scalability considerations, and cost management.

#### **Revised Example:**

> "Certainly! Here's an overview of the AWS services I've worked with and how I've utilized them in my projects:
>
> **1. AWS Lambda:**
> - **Usage:** I used AWS Lambda to run serverless functions for tasks like processing incoming data, handling API requests, and automating backend processes without managing servers.
> - **Example:** In the Hines project, I implemented Lambda functions to process patient claim data asynchronously, ensuring scalability and reducing latency.
>
> **2. Amazon DynamoDB:**
> - **Usage:** Utilized DynamoDB for storing and retrieving key-value pairs and document data, benefiting from its low latency and scalability.
> - **Example:** Implemented DynamoDB to store session data and user preferences, allowing for quick access and high availability.
>
> **3. Amazon CloudWatch:**
> - **Usage:** Employed CloudWatch for monitoring application performance, collecting and tracking metrics, and setting up alarms for critical events.
> - **Example:** Set up CloudWatch alarms to monitor API response times and trigger notifications if they exceed predefined thresholds.
>
> **4. Amazon SQS (Simple Queue Service) and SNS (Simple Notification Service):**
> - **Usage:** Used SQS for decoupling and scaling microservices by queuing tasks, and SNS for sending notifications and messages to multiple subscribers.
> - **Example:** In the Curie project, SQS was used to queue patient claim processing tasks, ensuring reliable and orderly handling of high volumes. SNS was used to notify users via email upon successful claim processing.
>
> **5. AWS CodePipeline and CodeBuild:**
> - **Usage:** Integrated these services to set up CI/CD pipelines, automating the build, test, and deployment processes.
> - **Example:** Configured CodePipeline to automatically build Docker images with CodeBuild whenever new code is pushed to the repository, streamlining deployments to Kubernetes clusters.
>
> **6. AWS S3 (Simple Storage Service):**
> - **Usage:** Leveraged S3 for storing and serving static files, backups, and logs.
> - **Example:** Stored application logs in S3 buckets for durable and scalable log storage, enabling easier access and analysis.
>
> **Best Practices Implemented:**
> - **Security:** Ensured that IAM roles and policies followed the principle of least privilege to secure AWS resources.
> - **Scalability:** Designed architectures that could scale horizontally, using services like Lambda and DynamoDB to handle varying loads efficiently.
> - **Cost Management:** Monitored and optimized the usage of AWS resources to manage costs effectively, utilizing services like CloudWatch for tracking usage patterns.

---

### **Stage 10: Data Security and Encryption**

#### **Question:**  
*How do you mask the data in the database?*

#### **Your Response:**
> "See Mask masking with the stars. Yes. Yes. Yes. Only the mask queue.
>
> Yeah. We need to provide 1, cryptographic, secret key for the encryption. That key only known by our developers only. So nobody can use that key. Like, nobody can know.
>
> It only stores in ENV. We're using that key. We encrypt them whatever that required fields. Like, a card fields will only, encrypt, and we'll store that data. So we are not going to share this secret key to anyone.
>
> So in this way, it, by default. Where where does your encryption key deal, and how do you rotate that key? We can rotate that key, but we have not implemented that key rotation. Because of this approach, you see, the stars data only valid for only 7 days. After 7 days, it automatically deletes from the DB.
>
> That also we have done because, you can't keep the data, right, the entire long days. So what we have done, we created a cross but not any other dial cascade. Thank you. Oh, we shared in EMI's. So it is you shared That that custom key we generated.
>
> That custom key we generated using that chart 256. I'll get some daylight. We generate That's fine. And, one one developer would have generated that. How does he So for dev environment, we will use same file, same EMV file for everyone.
>
> Correct. I don't place every sorry. Yeah. How do you share that EMV file? Is upload it somewhere or No.
>
> No. No. It's in project repo only, that ENV file. So you are sending that ENV file. That's in git ignore.
>
> You specify the git ignore dot ENV is ignored file, and we will share that ENV file via Teams, only the people. So it's not like all But we implement a secure way for developers to share this team of Teams or email. How how would you do that? Then this is not actually we have to implement it more securely because only 3 to 4 people have developed us, and so we are doing like this. We need to think in a way like, custom key accept Sure.
>
> Policies we need to try. Yeah. So how would you go about implementing the Internet? What would you do? We have which name rotation of the queue?
>
> Rotation, we will take on every weekly basis. We will keep rotation instead of daily basis. And so we will need to rotate it. The problem is the all stakeholders get to know about that. We need to know about that.
>
> We need to know about that. Okay. Go with that. We need to send that through the admin emails. Like, this encryption key got updated.
>
> So that's, I think, one way. But, it's not a good way to send those stakeholders direct encryption key because my emails might be compromised. Right? Mhmm. Yeah.
>
> Okay. So the one one aspect to what you told me is about this kind of, batch processing. Did you develop this service? I see you have developed some microservices. Yes.
>
> So can you talk about that a bit more on what that service does and, what kind of service architecture did you put in? You, like, you want you want to discuss about batch processing or, like, microservices, like, like No. Microservice. Microservice. Yeah.
>
> ..."

#### **Strengths:**
- **Security Measures:** Demonstrated understanding of data encryption and the importance of securing encryption keys.
- **Access Control:** Highlighted restricting access to sensitive data through environment variables and limited key distribution.

#### **Areas for Improvement:**
- **Technical Accuracy:** Clarify technical terms and ensure accurate descriptions (e.g., differentiate between `chown` and `chmod`).
- **Key Management Best Practices:** Discuss more secure and scalable key management solutions beyond storing keys in environment variables.
- **Data Masking Techniques:** Elaborate on actual data masking techniques rather than vague references to "stars."
- **Clarity and Structure:** The response was scattered and included unrelated topics. Aim for a clear, focused explanation.
- **Avoiding Jargon:** Use precise terminology to convey your points effectively.

#### **Revised Example:**

> "To mask sensitive data in the database, I implemented data encryption and masking techniques to ensure that sensitive information like patient health details remains secure.
>
> **Data Encryption:**
> - **Implementation:** I used Django's built-in encryption features to encrypt sensitive fields before storing them in the database. For instance, fields like credit card numbers and personal identification information are encrypted using AES-256 encryption.
> - **Key Management:** The encryption keys are stored securely in environment variables, which are not committed to the repository. Only authorized developers have access to these keys, and they are shared through secure channels like encrypted emails or secure vaults.
> - **Example:**
>   ```python
>   from django.db import models
>   from django_cryptography.fields import encrypt
> 
>   class Patient(models.Model):
>       name = models.CharField(max_length=100)
>       ssn = encrypt(models.CharField(max_length=11))
>   ```
>
> **Data Masking:**
> - **Implementation:** For scenarios where full data visibility is not required, I implemented data masking to display only parts of the sensitive information. For example, showing only the last four digits of a social security number.
> - **Example:**
>   ```python
>   def masked_ssn(self):
>       return f"***-**-{self.ssn[-4:]}"
>   ```
>
> **Key Rotation:**
> - **Current Practice:** While we have not yet implemented automated key rotation, we plan to rotate encryption keys on a weekly basis to enhance security.
> - **Proposed Improvement:** Moving forward, we intend to use AWS Key Management Service (KMS) for more secure and manageable key rotation, reducing the risk associated with manual key management.
>
> **Data Retention:**
> - **Implementation:** To comply with data protection regulations, we set data to expire and be automatically deleted after seven days. This ensures that sensitive information does not remain in the database longer than necessary.
>
> **Best Practices:**
> - **Secure Storage:** Ensured that encryption keys are never hard-coded and are stored securely outside of the codebase.
> - **Access Control:** Limited access to encryption keys to only those developers who require it, following the principle of least privilege.
> - **Compliance:** Adhered to HIPAA standards for handling medical information, ensuring that all data protection measures meet regulatory requirements."

---

### **Stage 11: Batch Processing and Microservices**

#### **Question:**  
*Can you talk about the microservices you developed and the architecture you implemented?*

#### **Your Response:**
> "This is like, basically, we have indexes.
>
> Right? Actually, for every medical course, we have an index for suppose. Let's take a favor. Favor is index with f. Let's take any motions or x.
>
> It's an index with f and a. Right? So these are indexes. These indexes are directly stored in a redis as a JSON document by using redis, f t index. We fetch this based on the code level.
>
> If you use a Django like, Redis is in memory. Right? So it's very fast to reduce the AP latency compared to normal DP operations, like, DB rates. So we used the Redis here for the why we used it? Because it's like providing medical terms.
>
> ..."

#### **Strengths:**
- **Use of Microservices:** Demonstrated experience in developing microservices, which is valuable for scalable and maintainable systems.
- **Redis Integration:** Utilized Redis for caching to improve application performance and reduce latency.
- **Performance Optimization:** Recognized the importance of reducing API latency through efficient caching strategies.

#### **Areas for Improvement:**
- **Comprehensive Explanation:** Provide a clear overview of the microservices architecture, including how services communicate, handle data, and scale.
- **Specific Technologies:** Mention specific technologies or frameworks used within the microservices beyond Redis.
- **Challenges and Solutions:** Elaborate on the challenges faced during microservices implementation and how you overcame them.
- **Code Examples:** Incorporate code snippets or diagrams to illustrate the architecture and interactions between services.

#### **Revised Example:**

> "In my current role at Waterlabs AI, I developed microservices to handle specific functionalities within our medical applications, Curie and Hines. Here's an overview of the microservices architecture and how I implemented it:
>
> **Architecture Overview:**
> - **Service Segmentation:** Divided the application into distinct services such as User Management, Billing Processing, Medical Information, and API Gateway.
> - **Communication:** Utilized RESTful APIs for synchronous communication between services and RabbitMQ for asynchronous message passing.
> - **Data Storage:** Implemented PostgreSQL as the primary database for transactional data and Redis for caching frequently accessed data, such as medical terms and billing information.
>
> **Key Microservices Developed:**
>
> **1. User Management Service:**
> - **Functionality:** Handles user registration, authentication, and profile management.
> - **Technologies:** Built with Flask, using JWT for secure authentication tokens.
> - **Caching:** Utilized Redis to cache user sessions, reducing database load and improving response times.
>
> **2. Billing Processing Service:**
> - **Functionality:** Processes medical billing, integrates with third-party insurance APIs to validate and calculate claim amounts.
> - **Technologies:** Developed using Django, leveraging Celery for background task processing.
> - **Caching:** Stored billing indexes in Redis as JSON documents for quick retrieval, minimizing API call latency.
>
> **3. Medical Information Service:**
> - **Functionality:** Provides detailed information about medical conditions, including descriptions and treatment plans.
> - **Technologies:** Built with FastAPI, ensuring high performance and low latency.
> - **Caching:** Implemented Redis to store and retrieve medical terms efficiently, enhancing the global search and auto-suggestion features.
>
> **Implementation Details:**
> - **API Gateway:** Set up an API Gateway using NGINX to route incoming requests to the appropriate microservices, enabling centralized access control and load balancing.
> - **Service Discovery:** Employed Consul for service discovery, allowing microservices to locate and communicate with each other dynamically.
> - **Monitoring and Logging:** Integrated Prometheus and Grafana for real-time monitoring, and ELK Stack (Elasticsearch, Logstash, Kibana) for centralized logging and analysis.
>
> **Challenges and Solutions:**
> - **Latency Issues:** Initially faced high API latency due to frequent database reads. To address this, I implemented Redis caching for medical indexes, reducing response times by 40%.
> - **Data Consistency:** Ensured data consistency across services by implementing eventual consistency mechanisms and using message queues to synchronize data updates.
> - **Scalability:** Designed the services to scale horizontally by containerizing them with Docker and orchestrating with Kubernetes, allowing us to handle increased loads seamlessly.
>
> **Batch Processing Service:**
> - **Functionality:** Automated the processing of large datasets, such as patient claims from Excel files.
> - **Implementation:** Developed a Flask-based service that ingests Excel files, processes each row by interacting with third-party APIs, stores the results in the database, and sends notifications via email.
> - **Optimization:** Implemented retry mechanisms with exponential backoff using Celery to handle network issues and ensure reliable processing.
> - **Deployment:** Containerized the service with Docker, deployed it on Kubernetes, and set up auto-scaling policies to manage varying workloads effectively."

---

### **Stage 12: Conclusion and Final Questions**

#### **Question:**  
*Do you have any questions for me?*

#### **Your Response:**
> "Adar ma, like, how many positions are open for this role? I just asked.
>
> Right? How how do you look at how many positions? Because sometimes, see, if the positions are more, the criteria might be different. If positions are less, the competition would be very less. Right?
>
> So that's the thing. Okay. And, what would be the roles and responsibilities if I got selected? Like, we just want Some of, backend and DevOps. So, active.
>
> Okay. Fine. Fine. 10 years, basically. That's okay.
>
> Yes. Yes. It will be end. Not at all. Thanks.
>
> Nice talking to you. Thank you, Carlos. Yes. Nice talking to you. I will get the band.
>
> Yeah. You too."

#### **Strengths:**
- **Engagement:** Demonstrated interest in understanding the role and the number of open positions.
- **Clarification:** Sought to understand the roles and responsibilities, which shows eagerness to align expectations.

#### **Areas for Improvement:**
- **Professionalism:** The response included informal language and abrupt topic changes, which can be perceived as unprofessional.
- **Finalization:** The conclusion was somewhat abrupt and included inappropriate language ("Oh, fuck"), which is highly unprofessional.
- **Active Listening:** Ensure responses are relevant and maintain focus on the questions being asked.

#### **Revised Example:**

> "Yes, I do have a couple of questions:
>
> **1. How many positions are available for this role?**
> - Understanding the number of openings will help me gauge the team structure and the potential for collaboration.
>
> **2. Can you elaborate on the specific roles and responsibilities associated with this position?**
> - I'd like to know more about the day-to-day tasks, the technologies I'll be working with, and how this role contributes to the overall goals of the team and company.
>
> **3. What does success look like in this position, and how is it measured?**
> - Understanding the key performance indicators will help me align my efforts to meet and exceed expectations.
>
> **4. Can you tell me more about the team I would be working with?**
> - Learning about the team's dynamics, expertise, and collaboration methods will give me insight into how I can contribute effectively.
>
> **5. What opportunities are there for professional development and growth within the company?**
> - I'm interested in continuing to develop my skills and taking on new challenges, so knowing the paths available would be beneficial.
>
> Thank you for the opportunity to ask these questions. I'm excited about the possibility of contributing to your team."

---

## **General Feedback and Recommendations**

### **1. Preparation and Practice**
- **Mock Interviews:** Continue engaging in mock interviews to build confidence and improve the clarity of your responses.
- **Coding Practice:** Regularly solve coding problems on platforms like LeetCode or HackerRank to enhance your problem-solving speed and accuracy.
- **System Design:** Prepare for system design questions by studying scalable architectures, microservices patterns, and best practices.

### **2. Communication Skills**
- **Clarity and Conciseness:** Strive to present your thoughts in a clear and concise manner. Avoid rambling by organizing your answers before speaking.
- **Structured Responses:** Utilize frameworks like STAR (Situation, Task, Action, Result) to structure your responses, making them more impactful and easier to follow.
- **Professionalism:** Maintain a professional demeanor throughout the interview. Avoid using informal language or expressions that might be perceived as unprofessional.

### **3. Technical Depth**
- **In-Depth Knowledge:** While you cover a broad range of topics, ensure you can delve deeper into each area when prompted. Be prepared to discuss the intricacies of technologies you've worked with.
- **Latest Trends:** Stay updated with the latest developments in your field, especially in rapidly evolving areas like cloud services, DevOps practices, and data security.

### **4. Handling Challenges**
- **Problem-Solving Approach:** Clearly articulate your problem-solving strategies, especially when facing challenges or unexpected issues.
- **Resilience:** Demonstrate resilience and adaptability by explaining how you've overcome obstacles in past projects.

### **5. Security Practices**
- **Comprehensive Security:** Expand on your security implementations by discussing encryption standards, authentication mechanisms, and compliance with industry regulations.
- **Best Practices:** Highlight your adherence to best practices in security, such as secure key management, regular audits, and vulnerability assessments.

---

## **Final Thoughts**

Your extensive experience and involvement in complex projects are significant assets. By refining how you present your experiences and deepening your technical explanations, you'll enhance your interview performance. Remember to stay calm, structured, and clear in your responses. Practicing these aspects will help you convey your expertise effectively and leave a strong impression on interviewers.

If you have specific questions or need further assistance with particular topics, feel free to ask!